---
layout: post
title: "Foundations of log Analysis"
subtitle: "Foundations for Blue Team Visibility"
category: soc
tags: logs blue-team siem detection siem
titles_from_headings: false
---

- TOC
{:toc}

## 1.1 What Are Logs and Why They Matter

### Introduction to Logs

In cybersecurity operations, especially from a Blue Team perspective, logs are fundamental to visibility, monitoring, and response. They represent the footprints of everything that happens in a system, application, or network. Without logging, detecting abnormal behavior or tracking malicious activity becomes nearly impossible.

A log is a timestamped record generated by a system, application, service, device, or security tool. Logs document events such as user authentications, process executions, network connections, file accesses, configuration changes, system errors, or security policy violations.

### Types of Logs (by Source)

| Source                     | Log Example                       | Use Case for Blue Team                               |
| -------------------------- | --------------------------------- | ---------------------------------------------------- |
| Operating System (Linux)   | `/var/log/auth.log`               | SSH login attempts, sudo usage                       |
| Operating System (Windows) | `Security.evtx`                   | Logons, process creations, privilege usage           |
| Network Devices            | Firewall logs, DHCP logs          | Blocked traffic, address leasing                     |
| Web Servers                | Apache, Nginx access/error logs   | Suspicious URIs, 404 fuzzing, directory traversal    |
| Security Tools             | EDR, antivirus, SIEM logs         | Threat detections, lateral movement                  |
| Cloud Infrastructure       | AWS CloudTrail, Azure Activity Log| API misuse, privilege escalation attempts            |

### Event vs Log

- **Event:** A single instance or action (e.g., "User X logged in").
- **Log:** The written record of an event, possibly structured (JSON) or unstructured (plaintext).

Every log contains at least a timestamp, the source or system, and the description of the event. Additional fields depend on the software or hardware generating the log.

### Real Examples of Log Entries

1. **Linux SSH Authentication Failure**

   ```text
   Jun 20 18:45:32 ubuntu sshd[25411]: Failed password for root from 192.168.1.23 port 49522 ssh2
   ```

   - **Interpretation:** The system rejected an SSH password attempt for the root user from IP 192.168.1.23.
   - **Use Case:** Correlate multiple failed attempts to detect brute-force activity.

2. **Windows Logon Event (Security.evtx, Event ID 4624)**

   ```text
   Log Name:  Security
   Event ID:  4624
   Logon Type: 10
   Account Name: Administrator
   Source Network Address: 10.0.0.14
   ```

   - **Interpretation:** A successful Remote Desktop Protocol (RDP) logon from 10.0.0.14 to the Administrator account.
   - **Use Case:** Detect unauthorized RDP access or lateral movement.

3. **Web Server Access Log (Apache)**

   ```text
   192.168.1.50 - - [29/Jun/2025:14:23:42 +0000] "GET /admin HTTP/1.1" 401 487
   ```

   - **Interpretation:** Client 192.168.1.50 attempted to access a restricted area (`/admin`) and received 401 Unauthorized.
   - **Use Case:** Detect probing or web-based brute-force against login or admin portals.

4. **IDS Alert (Suricata JSON format)**

   ```json
   {
     "timestamp": "2025-06-29T16:21:00.512293Z",
     "event_type": "alert",
     "src_ip": "192.168.1.10",
     "dest_ip": "10.10.1.23",
     "alert": {
       "signature": "ET SCAN Nmap -sS Syn Scan",
       "severity": 2
     }
   }
   ```

   - **Interpretation:** IDS identified a SYN scan likely from Nmap.
   - **Use Case:** Alert triage, source attribution, and correlation in SIEM.

### Why Logs Are Critical for Blue Teams

1. **Visibility:** Logs provide insight into user activity, system changes, and potential threats.
2. **Forensics:** In post-incident investigation, logs are often the only timeline available.
3. **Detection Engineering:** Detection rules (e.g., in SIEM or EDR) rely on log-based patterns.
4. **Compliance and Auditing:** Regulatory frameworks like PCI-DSS, HIPAA, and ISO 27001 require evidence of logging.
5. **Threat Hunting:** Hypothesis-based searches through logs can reveal stealthy attackers.

### Common Blue Team Use Cases Involving Logs

| Use Case                           | Related Log Type(s)                              |
| ---------------------------------- | ------------------------------------------------ |
| Detect brute-force attacks         | SSH logs, Event ID 4625 (Windows)                |
| Investigate privilege abuse        | Event ID 4672 (Windows), sudo logs (Linux)       |
| Detect suspicious command execution| Event ID 4688, Sysmon, bash_history              |
| Trace lateral movement             | RDP logs, SMB connections, port scans            |
| Identify web attack vectors        | Apache or Nginx access logs, WAF logs            |
| Monitor file access or exfiltration| File integrity logs, EDR telemetry               |

### Logging Pitfalls to Avoid

- **No central logging:** Local logs are easily erased by attackers.
- **No time sync (NTP):** Event correlation becomes unreliable.
- **Unstructured logging:** Makes automation and parsing harder.
- **Insufficient retention:** Historical analysis becomes impossible.
- **Too much noise:** Without filtering, important signals get buried.

Logs are the foundation of security operations. Whether responding to incidents, building detections, or hunting for threats, Blue Teams depend on accurate, complete, and well-structured log data. Understanding the types of logs, their format, and their role in daily security tasks is the first step toward mastering log analysis.

## 1.2 Common Log Formats and Structures

### Introduction to Log Formats

Effective log analysis requires not only understanding what logs are, but also how they are structured. Logs come in many formats depending on their origin, such as operating systems, network devices, security tools, and web servers. A Blue Team analyst must be able to quickly identify the format of a log, parse its key fields, and extract relevant information for triage, detection, and investigation.

Logs may be structured, semi-structured, or unstructured. The format used affects how easily logs can be ingested by SIEM platforms, parsed with tools, or correlated across systems.

### Log Format Categories

1. **Plain Text Logs**
   Common in Linux systems and legacy applications. These are human-readable and line-oriented but often require regular expressions or tools like `grep` for parsing.
2. **Key-Value Pair Logs**
   Each line contains space-separated key=value pairs. This structure allows basic parsing and filtering.
3. **CSV Logs**
   Comma-separated values, useful for exporting and analyzing in Excel or ingestion by SIEMs.
4. **JSON Logs**
   Structured logs used by modern applications and tools like Suricata, AWS CloudTrail, or Elastic Beats. Easily parsed by machines and log pipelines.
5. **XML Logs**
   Less common today but still used in legacy systems and some enterprise software.
6. **Binary Logs**
   Examples include Windows Event Logs (EVTX), which require special tools like Event Viewer or LogParser to read.

### Practical Examples by Format

1. **Plain Text - Linux Auth Log**

   ```text
   Jun 30 10:12:43 server sshd[1298]: Accepted password for admin from 192.168.0.12 port 50222 ssh2
   ```

   **Key elements:** timestamp, hostname, process (sshd), status message
   **Use case:** Authentication success, origin IP, user identity

2. **Key-Value Format - Systemd Journal Log**

   ```text
   MESSAGE=Failed password for invalid user test from 10.1.1.5 port 50022 ssh2
   PRIORITY=3
   SYSLOG_IDENTIFIER=sshd
   ```

   **Use case:** Useful in Red Hat-based systems using `journalctl`. Easier to extract specific fields.

3. **CSV Format - Firewall Log Export**

   ```text
   timestamp,src_ip,dest_ip,port,action
   2025-06-30 12:01:55,10.0.0.5,192.168.10.1,443,allow
   ```

   **Use case:** Easy import into SIEM or spreadsheets for analysis of firewall behavior.

4. **JSON Format - Suricata Alert**

   ```json
   {
     "timestamp": "2025-06-30T12:04:11.482Z",
     "event_type": "alert",
     "src_ip": "10.10.10.10",
     "dest_ip": "192.168.100.5",
     "alert": {
       "signature": "ET SCAN Nmap Scripting Engine",
       "severity": 2
     }
   }
   ```

   **Use case:** Structured format makes this ideal for parsing in SIEMs or log pipelines like ELK. Allows querying fields such as `alert.signature` or `src_ip`.

5. **XML Format - Web Application Firewall Log**

   ```xml
   <event>
     <date>2025-06-30</date>
     <src_ip>172.16.0.8</src_ip>
     <event_type>SQL Injection Attempt</event_type>
   </event>
   ```

   **Use case:** Some older or enterprise tools output XML. Requires XPath or similar methods for extraction.

6. **EVTX (Binary) - Windows Event Log**

   Can be viewed using:

   - Event Viewer GUI
   - `Get-WinEvent` or `wevtutil` via PowerShell
   - LogParser or SIEM agent ingestion

   Example (Security.evtx, Event ID 4688):

   ```text
   A new process has been created.
   New Process Name: C:\Windows\System32\cmd.exe
   Creator Process: C:\Windows\explorer.exe
   ```

   **Use case:** Detecting suspicious process execution like cmd.exe, powershell.exe, or rundll32.exe.

### Field Standardization and Normalization

Since each log source has its own schema, one of the biggest challenges in centralized log analysis is normalization. This is the process of converting different log formats and fields into a common schema.

For example:

| Raw Field (Vendor-specific)      | Normalized Field |
| -------------------------------- | ---------------- |
| src_ip, source-address, ip.src   | source_ip        |
| username, user, acct             | user_name        |
| timestamp, @timestamp, time      | event_time       |

This standardization is critical in SIEM platforms like Splunk, Elastic Security, or QRadar to build detection rules that work across multiple data sources.

### Practical Considerations for Blue Teams

- Use parsing and enrichment tools like Logstash, Fluent Bit, or syslog-ng to convert and enrich log data.
- Build dashboards based on normalized fields for cross-platform visibility.
- Validate that log sources produce structured outputs whenever possible to ease correlation and search.
- Understand how your SIEM ingests and parses each log type.

Understanding log formats is a core skill for any Blue Team professional. Each source system, whether it is an operating system, firewall, or application, produces logs in its own format, and these formats directly affect how logs can be ingested, parsed, and analyzed.

Being able to recognize and work with different formats such as plaintext, JSON, CSV, and binary (like Windows EVTX) is essential for building effective detection rules, hunting threats, and conducting forensic investigations. Additionally, the process of normalizing logs across different systems ensures that security operations teams can correlate events accurately and build scalable detection logic.

## 1.3 Timestamps, Timezones, and Synchronization (NTP)

### Introduction to Timestamps

Accurate timestamps are one of the most critical components of effective log analysis. Time-based correlation is the backbone of detecting, investigating, and reconstructing security incidents. When timestamps are misaligned across different systems, analysts may misinterpret the sequence of events or completely overlook key indicators.

Ensuring that all systems use consistent and synchronized time is a fundamental practice in cybersecurity operations. This is accomplished using Network Time Protocol (NTP), which allows devices to regularly update their internal clocks from a trusted time source.

### Understanding Timestamps

Most logs contain timestamps that indicate when an event occurred. However, the format, timezone, and precision of these timestamps can vary significantly depending on the source.

Common timestamp formats:

1. **Human-readable local time**

   ```text
   Jun 30 14:22:43
   2025-06-30 18:45:12
   ```

2. **UTC time with timezone offset**

   ```text
   2025-06-30T18:45:12+00:00
   2025-06-30T18:45:12Z
   ```

3. **Epoch/Unix time** (seconds since 1970-01-01)

   ```text
   Timestamp: 1751372712 -> Human time: 2025-06-30 18:45:12 UTC
   ```

4. **High-precision timestamp** (milliseconds or microseconds)

   ```text
   2025-06-30T18:45:12.783Z
   2025-06-30 14:22:43.154 +0200
   ```

Each of these formats may be used in different environments or tools, such as syslog, web server logs, cloud logs, or SIEM platforms.

### Timezone Discrepancies in Log Analysis

Timezone misalignment is a common problem during incident investigation. For example, if a firewall logs in UTC, a Linux server logs in local time (UTC-3), and an application server logs in UTC+1, then the same event might appear to occur at three different times.

This leads to:

- Misinterpretation of event order
- Gaps in correlation logic
- Incorrect incident timelines
- False positives in detection rules

**Example scenario** (same authentication event in different systems):

Linux server (UTC-3):

```text
Jun 30 15:12:02 sshd[2991]: Accepted password for joao from 10.0.0.10
```

Firewall (UTC):

```text
2025-06-30T18:12:02Z src=10.0.0.10 dst=192.168.1.20 action=accept
```

Application log (UTC+1):

```text
2025-06-30 19:12:02 user=joao login_success=true
```

Although all these events refer to the same authentication session, the timestamps differ by hours. Without a standardized time reference, incident correlation becomes unreliable.

### Network Time Protocol (NTP)

NTP is a protocol that synchronizes system clocks with designated time servers. When implemented correctly, it ensures that all systems within an infrastructure maintain consistent time, typically synchronized to Coordinated Universal Time (UTC).

#### Linux Configuration

To enable and verify NTP synchronization:

```bash
sudo timedatectl set-ntp true
timedatectl status
```

Output example:

```text
Local time: Mon 2025-06-30 15:00:00 -03
Universal time: Mon 2025-06-30 18:00:00 UTC
NTP synchronized: yes
```

#### Windows Configuration

NTP settings are controlled via Control Panel or PowerShell:

```powershell
w32tm /query /status
w32tm /resync
```

#### Best Practices

- Use a central internal NTP server or a pool of public NTP servers.
- Avoid relying on system BIOS or hardware clocks.
- Monitor and alert on systems that deviate from expected time accuracy.
- Normalize timestamps to UTC in SIEM platforms to ensure consistent correlation.

### Timestamp Normalization in Log Pipelines

Many organizations normalize timestamps at the log ingestion stage. For example, Logstash or Fluent Bit can parse and convert various timestamp formats into a standardized field like `@timestamp` in UTC.

Logstash example:

```text
filter {
  date {
    match => [ "log_time", "yyyy-MM-dd HH:mm:ss" ]
    target => "@timestamp"
    timezone => "UTC"
  }
}
```

SIEMs like Splunk or Elastic Search rely heavily on timestamp parsing for alerting, correlation, and timeline views. Incorrectly parsed or missing timestamps often cause events to be indexed out of order or excluded from detection logic.

## 1.4 Log Rotation and Retention Policies

### Introduction to Log Rotation

As systems and applications run continuously, logs can grow rapidly and consume significant disk space if not properly managed. Uncontrolled log growth may lead to system instability, data loss, or inability to retain important forensic evidence. Blue Team professionals must understand and implement log rotation and retention strategies to ensure performance, availability, and security compliance.

Log rotation refers to the process of archiving, compressing, or deleting old log files after a specific time interval or when a size threshold is reached. Retention policies define how long logs should be stored and which logs are critical to preserve for auditing, detection, or investigation.

### Why Log Management Is Critical

1. **Disk space control:** Prevents logs from filling up the disk and crashing services.
2. **Forensic preservation:** Ensures key evidence is available during an incident investigation.
3. **Compliance:** Many frameworks (e.g., PCI-DSS, HIPAA, ISO 27001) require logs to be retained for months or years.
4. **Performance:** Overly large log files can slow down parsing tools and SIEM ingestion.
5. **Alerting:** Missed log rotation may indicate misconfiguration or malicious log tampering.

### Log Rotation in Practice

#### Linux Systems

Most Linux distributions use `logrotate`, a utility that manages the rotation, compression, and deletion of log files. It is configured via `/etc/logrotate.conf` and individual files in `/etc/logrotate.d/`.

Example:

```text
/var/log/auth.log {
   weekly
   rotate 4
   compress
   missingok
   notifempty
}
```

This configuration means:

- Logs are rotated weekly.
- Only 4 archives are kept.
- Old logs are compressed (e.g., `.gz`).
- Rotation is skipped if the file is empty.
- If the file is missing, no error is raised.

Manual test:

```text
sudo logrotate --debug /etc/logrotate.conf
```

#### Windows Systems

Windows Event Logs rotate automatically based on file size or overwrite policy. These settings can be changed via Event Viewer.

Steps:

1. Open Event Viewer -> Right-click a log (e.g., Security) -> Properties
2. Set maximum log size (e.g., 200 MB)
3. Choose action: Overwrite events, archive logs, or stop logging

PowerShell check:

```powershell
Get-EventLog -LogName Security | Measure-Object
```

### Retention Policy Design

Log retention depends on multiple factors:

- Regulatory requirements
- Internal security policy
- Storage capacity
- Business risk and criticality of system

Typical retention guidelines:

| Log Type                       | Recommended Retention |
| ------------------------------ | --------------------- |
| Authentication logs (SSH, RDP) | 180-365 days          |
| Security logs (EDR, SIEM)      | 1-3 years             |
| Web server access logs         | 90-180 days           |
| Firewall, IDS/IPS logs         | 90-365 days           |
| Cloud API activity logs        | 180-365 days          |
| Compliance-regulated systems   | 1-7 years             |

### Retention Tools and Strategies

- Centralize logs in SIEM or cloud storage (e.g., S3, Azure Blob)
- Implement cold storage tiers for infrequently accessed logs
- Encrypt archived logs to maintain confidentiality and integrity
- Tag logs with metadata to automate lifecycle management

### Security Considerations

- Prevent unauthorized access to archived logs
- Monitor for log deletion or tampering attempts
- Ensure log forwarding continues after rotation
- Validate that logs are not truncated during compression or archiving

### Log Forwarding Example (Linux rsyslog)

```text
*.* @192.168.1.10:514
```

This sends all log events to a centralized syslog server.

## 1.5 Log Access and Visualization Tools

### Introduction to Log Access

Collecting logs is only the first step. Security analysts must also be able to access, search, and visualize log data quickly and effectively to respond to incidents or perform investigations. Choosing the right tools for log access depends on factors like log format, source, volume, and team workflow.

This section focuses on tools and techniques used by Blue Team professionals to interact with logs efficiently in both local and centralized environments.

### Local Access Tools

In environments without centralized logging, logs are accessed directly from the system where they are generated. This is common in endpoint investigations, incident response scenarios, or when a SIEM is unavailable.

#### Command-Line Tools (Linux and macOS)

1. `cat` - View the contents of log files
2. `less` - Paginate logs interactively
3. `tail -f` - Follow logs in real time
4. `grep` - Search for patterns in logs
5. `awk`, `sed` - Filter and format output
6. `journalctl` - Query systemd journal logs
7. `jq` - Parse JSON logs

Examples

View the last 20 SSH login failures:

```text
grep "Failed password" /var/log/auth.log | tail -n 20
```

Follow system log updates in real time:

```text
tail -f /var/log/syslog
```

Parse and pretty-print Suricata JSON logs:

```text
cat eve.json | jq '.'
```

Query a specific time window with `journalctl`:

```text
journalctl --since "2025-06-30 14:00:00" --until "2025-06-30 14:10:00"
```

#### Windows Access Tools

1. **Event Viewer** - Graphical interface to browse logs
2. **PowerShell Cmdlets**
   - `Get-EventLog` (legacy)
   - `Get-WinEvent` (modern, supports XML queries)
3. **LogParser** - Query EVTX logs using SQL-like syntax
4. **Sysinternals Tools** - For live log monitoring (`PsLogList`, `Procmon`)

Examples

Get last 10 security events:

```powershell
Get-WinEvent -LogName Security -MaxEvents 10
```

Filter by Event ID:

```powershell
Get-WinEvent -FilterHashtable @{LogName='Security'; Id=4625}
```

### Text Editors and GUI Tools

For reviewing logs manually, especially plaintext or CSV logs, text editors are useful:

- Notepad++ - Supports regex search, syntax highlighting, large files
- Visual Studio Code - Extensible with log viewing plugins
- BareTail - Real-time log tailing on Windows
- Glogg - Multi-platform log explorer for large files
- Sublime Text - Lightweight with multiline search support

Use case: Quickly inspecting logs from EDR exports, firewall logs, or JSON from cloud exports.

### Centralized Log Management and SIEM Platforms

When logs are collected across multiple systems, centralized platforms provide scalable search and analysis capabilities.

Popular tools:

1. **Splunk**
   - Search logs using SPL (Search Processing Language)
   - Dashboards, alerts, and playbooks
   - Used in SOCs for triage and response
2. **Elastic Stack (ELK)**
   - Elasticsearch, Logstash, Kibana
   - Scalable search and visualization
   - Common in open-source SIEM implementations
3. **Graylog**
   - Centralized logging with stream-based alerts
   - Supports GELF and structured logging
   - Custom pipelines for log parsing
4. **SIEM-as-a-Service Tools**
   - Microsoft Sentinel, Chronicle, QRadar Cloud
   - Scalable ingestion, correlation rules, and ML-based alerts

### Example: Basic Splunk Search

Find failed logons from all Windows hosts:

```text
index=windows EventCode=4625 | stats count by Account_Name, host
```

Search for PowerShell usage with encoded commands:

```text
index=windows "powershell" "EncodedCommand"
```

### Example: ELK Query via Kibana

Filter all alerts from Suricata with severity 1:

```json
{
  "query": {
    "bool": {
      "must": [
        { "match": { "alert.severity": "1" } },
        { "match": { "event_type": "alert" } }
      ]
    }
  }
}
```

### Use Cases for Visualization

- Build dashboards to track login activity, geolocation of IPs, and command execution
- Visualize spikes in failed login attempts to detect brute-force attacks
- Create alert thresholds and timelines of incident activity
- Use correlation maps to connect events across hosts or networks

### Best Practices for Blue Team Log Access

- Build and maintain saved queries for common threat scenarios
- Use field extraction and parsing early in the pipeline
- Implement role-based access to sensitive logs
- Regularly audit log visibility to ensure coverage across systems
- Tailor visualizations to highlight anomalies, not just raw volume
